{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ashishpapanai/miniconda3/envs/timm/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from torchvision.transforms import (\n",
    "    CenterCrop,\n",
    "    Compose,\n",
    "    Normalize,\n",
    "    RandomHorizontalFlip,\n",
    "    RandomResizedCrop,\n",
    "    Resize,\n",
    "    ToTensor,\n",
    ")\n",
    "import torch\n",
    "\n",
    "# ImageNet_mean = [0.485, 0.456, 0.406]\n",
    "# ImageNet_std = [0.229, 0.224, 0.225]\n",
    "ImageNet_mean = [0.5, 0.5, 0.5]\n",
    "ImageNet_std = [0.5, 0.5, 0.5]\n",
    "normalize = Normalize(mean=ImageNet_mean, std=ImageNet_std)\n",
    "train_transforms = Compose(\n",
    "    [\n",
    "        RandomResizedCrop(224),\n",
    "        RandomHorizontalFlip(),\n",
    "        ToTensor(),\n",
    "        normalize,\n",
    "    ]\n",
    ")\n",
    "\n",
    "val_transforms = Compose(\n",
    "    [\n",
    "        # Resize(image_processor.size[\"height\"]),\n",
    "        Resize(224),\n",
    "        CenterCrop(224),\n",
    "        ToTensor(),\n",
    "        normalize,\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "def preprocess_train(example_batch):\n",
    "    \"\"\"Apply train_transforms across a batch.\"\"\"\n",
    "    example_batch[\"pixel_values\"] = [train_transforms(image.convert(\"RGB\")) for image in example_batch[\"image\"]]\n",
    "    return example_batch\n",
    "\n",
    "\n",
    "def preprocess_val(example_batch):\n",
    "    \"\"\"Apply val_transforms across a batch.\"\"\"\n",
    "    example_batch[\"pixel_values\"] = [val_transforms(image.convert(\"RGB\")) for image in example_batch[\"image\"]]\n",
    "    return example_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from loaders.ImageData import ImageDataset\n",
    "data_dir = \"/bucket/npss/CottonPestClassification_v3a_os_lora/\"\n",
    "data_dir_2 = \"/bucket/npss/CottonPestClassification_v3a_npss/\"\n",
    "\n",
    "# train_loader = ImageDataset(data_dir, split='train', transform=train_transforms)\n",
    "val_loader = ImageDataset(data_dir, split='val', transform=val_transforms)\n",
    "test_loader = ImageDataset(data_dir_2, split='reporting', transform=val_transforms)\n",
    "holdout_loader = ImageDataset(data_dir_2, split='holdout', transform=val_transforms)\n",
    "# val_loader = ImageDataset(data_dir, split='val')\n",
    "# test_loader = ImageDataset(data_dir, split='test')\n",
    "# holdout_loader = ImageDataset(data_dir, split='holdout')\n",
    "\n",
    "# label2id = train_loader.labels2id\n",
    "label2id = val_loader.labels2id\n",
    "# id2label = train_loader.id2label\n",
    "id2label = val_loader.id2label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load lora model from local\n",
    "from transformers import AutoModelForImageClassification\n",
    "from peft import LoraConfig, get_peft_model, PeftModel\n",
    "from transformers import AutoImageProcessor\n",
    "import timm\n",
    "import evaluate\n",
    "from timm.models import create_model, load_checkpoint\n",
    "from timm.data import resolve_data_config\n",
    "from timm.data.transforms_factory import create_transform\n",
    "\n",
    "# config = LoraConfig(\n",
    "#     r=16,\n",
    "#     lora_alpha=16,\n",
    "#     target_modules=[\"query\", \"value\"],\n",
    "#     lora_dropout=0.1,\n",
    "#     bias=\"none\",\n",
    "#     modules_to_save=[\"classifier\"],\n",
    "# )\n",
    "# config = LoraConfig(\n",
    "#     r=16,\n",
    "#     lora_alpha=16,\n",
    "#     target_modules=[\"qkv\"],\n",
    "#     lora_dropout=0.1,\n",
    "#     bias=\"none\",\n",
    "#     modules_to_save=[\"classifier\"],\n",
    "# )\n",
    "\n",
    "model_checkpoint = \"output/train/vit_base_patch16_224.orig_in21k-timm-050524-OS/model_best.pth.tar\"\n",
    "\n",
    "# model = AutoModelForImageClassification.from_pretrained(\n",
    "#     model_checkpoint,\n",
    "#     label2id=label2id,\n",
    "#     id2label=id2label,\n",
    "#     ignore_mismatched_sizes=True,\n",
    "# )\n",
    "model = timm.create_model('timm/vit_base_patch16_224.orig_in21k', \n",
    "                                pretrained=True, num_classes=3)\n",
    "transform = create_transform(**resolve_data_config(model.pretrained_cfg, model=model))\n",
    "# load_checkpoint(model, model_checkpoint, strict=False)\n",
    "\n",
    "inference_model = PeftModel.from_pretrained(\n",
    "                                    model,\n",
    "                                    'output/vit-base-patch16-224-lora-IN21k_NPSS_CheckNew_1004/checkpoint-11')\n",
    "# inference_model = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModulesToSaveWrapper(\n",
       "  (original_module): Linear(in_features=768, out_features=3, bias=True)\n",
       "  (modules_to_save): ModuleDict(\n",
       "    (default): Linear(in_features=768, out_features=3, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_processor = AutoImageProcessor.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # image_processor \n",
    "# ImageNet_mean = [0.485, 0.456, 0.406]\n",
    "# ImageNet_std = [0.229, 0.224, 0.225]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# outs = val_loader.__getitem__(0)\n",
    "# path = outs['image_file_path']\n",
    "# img = outs['image']\n",
    "# label = outs['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoding = image_processor(img, return_tensors=\"pt\")\n",
    "# with torch.no_grad():\n",
    "#     # check = {'pixel_values': img}\n",
    "#     output = inference_model(**encoding)\n",
    "#     logits = output.logits\n",
    "#     probs = logits.softmax(dim=1)\n",
    "#     print(probs, probs.argmax(dim=1), label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoding['pixel_values'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_outs_df = pd.DataFrame(columns=['image_file_path', 'label', 'pred_label', 'pred_prob', 'logits'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 1050/1413 [06:06<04:25,  1.37it/s]/home/ashishpapanai/miniconda3/envs/timm/lib/python3.10/site-packages/PIL/Image.py:3186: DecompressionBombWarning: Image size (108576768 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n",
      "100%|██████████| 1413/1413 [09:54<00:00,  2.38it/s]\n"
     ]
    }
   ],
   "source": [
    "path_list, label_list, pred_label_list, pred_prob_list, logits_list = [], [], [], [], []\n",
    "for item in tqdm(val_loader):\n",
    "    path = item['image_file_path']\n",
    "    img = item['image']\n",
    "    label = item['labels']\n",
    "\n",
    "    # encoding = image_processor(img.convert(\"RGB\"), return_tensors=\"pt\")\n",
    "    # encoding_val = {'pixel_values': img.unsqueeze(0)}\n",
    "    with torch.no_grad():\n",
    "        output = inference_model(img.unsqueeze(0))\n",
    "        logits = output\n",
    "        probs = logits.softmax(dim=1)\n",
    "    \n",
    "    path_list.append(path)\n",
    "    label_list.append(label)\n",
    "    pred_label_list.append(probs.argmax(dim=1).item())\n",
    "    pred_prob_list.append(probs)\n",
    "    logits_list.append(logits)\n",
    "\n",
    "val_outs_df['image_file_path'] = path_list\n",
    "val_outs_df['label'] = label_list\n",
    "val_outs_df['pred_label'] = pred_label_list\n",
    "val_outs_df['pred_prob'] = pred_prob_list\n",
    "val_outs_df['logits'] = logits_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 1341/1867 [08:32<05:04,  1.73it/s]/home/ashishpapanai/miniconda3/envs/timm/lib/python3.10/site-packages/PIL/Image.py:3186: DecompressionBombWarning: Image size (108576768 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n",
      "100%|██████████| 1867/1867 [14:07<00:00,  2.20it/s]\n"
     ]
    }
   ],
   "source": [
    "test_outs_df = pd.DataFrame(columns=['image_file_path', 'label', 'pred_label', 'pred_prob', 'logits'])\n",
    "path_list_test, label_list_test, pred_label_list_test, pred_prob_list_test, logits_list_test = [], [], [], [], []\n",
    "for item in tqdm(test_loader):\n",
    "    path = item['image_file_path']\n",
    "    img = item['image']\n",
    "    label = item['labels']\n",
    "\n",
    "    # encoding = image_processor(img.convert(\"RGB\"), return_tensors=\"pt\")\n",
    "    # encoding_test = {'pixel_values': img.unsqueeze(0)}    \n",
    "    # print(img.shape, encoding['pixel_values'].shape)\n",
    "    with torch.no_grad():\n",
    "        # output = inference_model(**encoding_test)\n",
    "        output = inference_model(img.unsqueeze(0))\n",
    "        # logits = output.logits\n",
    "        logits = output\n",
    "        probs = logits.softmax(dim=1)\n",
    "    \n",
    "    path_list_test.append(path)\n",
    "    label_list_test.append(label)\n",
    "    pred_label_list_test.append(probs.argmax(dim=1))\n",
    "    pred_prob_list_test.append(probs)\n",
    "    logits_list_test.append(logits)\n",
    "\n",
    "test_outs_df['image_file_path'] = path_list_test\n",
    "test_outs_df['label'] = label_list_test\n",
    "test_outs_df['pred_label'] = pred_label_list_test\n",
    "test_outs_df['pred_prob'] = pred_prob_list_test\n",
    "test_outs_df['logits'] = logits_list_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 101/101 [00:40<00:00,  2.48it/s]\n"
     ]
    }
   ],
   "source": [
    "npss_outs_df = pd.DataFrame(columns=['image_file_path', 'label', 'pred_label', 'pred_prob', 'logits'])\n",
    "path_list_npss, label_list_npss, pred_label_list_npss, pred_prob_list_npss, logits_list_npss = [], [], [], [], []\n",
    "for item in tqdm(holdout_loader):\n",
    "    path = item['image_file_path']\n",
    "    img = item['image']\n",
    "    label = item['labels']\n",
    "\n",
    "    # encoding = image_processor(img.convert(\"RGB\"), return_tensors=\"pt\")\n",
    "    encoding_hold = {'pixel_values': img.unsqueeze(0)}\n",
    "    with torch.no_grad():\n",
    "        # output = inference_model(**encoding_hold)\n",
    "        output = inference_model(img.unsqueeze(0))\n",
    "        # logits = output.logits\n",
    "        logits = output\n",
    "        probs = logits.softmax(dim=1)\n",
    "    \n",
    "    path_list_npss.append(path)\n",
    "    label_list_npss.append(label)\n",
    "    pred_label_list_npss.append(probs.argmax(dim=1))\n",
    "    pred_prob_list_npss.append(probs)\n",
    "    logits_list_npss.append(logits)\n",
    "\n",
    "npss_outs_df['image_file_path'] = path_list_npss\n",
    "npss_outs_df['label'] = label_list_npss\n",
    "npss_outs_df['pred_label'] = pred_label_list_npss\n",
    "npss_outs_df['pred_prob'] = pred_prob_list_npss\n",
    "npss_outs_df['logits'] = logits_list_npss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(label\n",
       " 1    928\n",
       " 2    452\n",
       " 0     33\n",
       " Name: count, dtype: int64,\n",
       " pred_label\n",
       " 1    945\n",
       " 2    273\n",
       " 0    195\n",
       " Name: count, dtype: int64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_outs_df.label.value_counts(), val_outs_df.pred_label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# npss_outs_df.label.value_counts(), npss_outs_df.pred_label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_outs_df['pred_label'] = val_outs_df['pred_label'].apply(lambda x: x.item())\n",
    "test_outs_df['pred_label'] = test_outs_df['pred_label'].apply(lambda x: x.item())\n",
    "npss_outs_df['pred_label'] = npss_outs_df['pred_label'].apply(lambda x: x.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "val_acc = accuracy_score(val_outs_df['label'], val_outs_df['pred_label'])\n",
    "val_prec = precision_score(val_outs_df['label'], val_outs_df['pred_label'], average=None)\n",
    "val_recall = recall_score(val_outs_df['label'], val_outs_df['pred_label'], average=None)\n",
    "val_f1 = f1_score(val_outs_df['label'], val_outs_df['pred_label'], average=None)\n",
    "\n",
    "test_acc = accuracy_score(test_outs_df['label'], test_outs_df['pred_label'])\n",
    "test_prec = precision_score(test_outs_df['label'], test_outs_df['pred_label'], average=None)\n",
    "test_recall = recall_score(test_outs_df['label'], test_outs_df['pred_label'], average=None)\n",
    "test_f1 = f1_score(test_outs_df['label'], test_outs_df['pred_label'], average=None)\n",
    "\n",
    "npss_acc = accuracy_score(npss_outs_df['label'], npss_outs_df['pred_label'])\n",
    "npss_prec = precision_score(npss_outs_df['label'], npss_outs_df['pred_label'], average=None)\n",
    "npss_recall = recall_score(npss_outs_df['label'], npss_outs_df['pred_label'], average=None)\n",
    "npss_f1 = f1_score(npss_outs_df['label'], npss_outs_df['pred_label'], average=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_outs_df['correct'] = val_outs_df['label'] == val_outs_df['pred_label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "correct\n",
       "True     1014\n",
       "False     399\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_outs_df.correct.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping:  {'aphids': 0, 'none': 1, 'whitefly': 2}\n",
      "Validation Accuracy:  0.7176\n",
      "Validation Precision:  [0.04615385 0.82857143 0.81318681]\n",
      "Validation Recall:  [0.27272727 0.84375    0.49115044]\n",
      "Validation F1:  [0.07894737 0.83609183 0.61241379]\n",
      "Test Accuracy:  0.7365\n",
      "Test Precision:  [0.22222222 0.81646091 0.79186603]\n",
      "Test Recall:  [0.57777778 0.85223368 0.53996737]\n",
      "Test F1:  [0.32098765 0.83396385 0.64209505]\n",
      "NPSS Accuracy:  0.7921\n",
      "NPSS Precision:  [0.83333333 0.16666667 0.82978723]\n",
      "NPSS Recall:  [0.8  1.   0.78]\n",
      "NPSS F1:  [0.81632653 0.28571429 0.80412371]\n"
     ]
    }
   ],
   "source": [
    "print(\"Mapping: \", label2id)\n",
    "print(\"Validation Accuracy: \", round(val_acc, 4))\n",
    "print(\"Validation Precision: \", val_prec)\n",
    "print(\"Validation Recall: \", val_recall)\n",
    "print(\"Validation F1: \", val_f1)\n",
    "\n",
    "print(\"Test Accuracy: \", round(test_acc, 4))\n",
    "print(\"Test Precision: \", test_prec)\n",
    "print(\"Test Recall: \", test_recall)\n",
    "print(\"Test F1: \", test_f1)\n",
    "\n",
    "print(\"NPSS Accuracy: \", round(npss_acc, 4))\n",
    "print(\"NPSS Precision: \", npss_prec)\n",
    "print(\"NPSS Recall: \", npss_recall)\n",
    "print(\"NPSS F1: \", npss_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_outs_df.to_csv('./output/vit-base-patch16-224-lora-IN21k_NPSS_OS_check.csv', index=False)\n",
    "test_outs_df.to_csv('./output/vit-base-patch16-224-lora-IN21k_NPSS_OS_check.csv', index=False)\n",
    "npss_outs_df.to_csv('./output/vit-base-patch16-224-lora-IN21k_NPSS_OS_check.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inference_model.push_to_hub('ashishp-wiai/vit-base-patch16-224-in21k-finetuned-CottonPestClassification_v3a_os')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "timm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
